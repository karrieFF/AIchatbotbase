Install quen3 locally:
https://nodeshift.cloud/blog/how-to-install-qwen-3-locally

Model development solve issues:
1. need low temparature to get relatively not createive findings
2. revise promopt to be concise and move the important part into front. 
3. Can not provide this, if I provide this, the model will provide the suggestions everytime.
    •	At the planning stage, if the client requests input, offer personalized suggestions with permission, based on:
        o	Their current activity level
        o	Health profile, limitations, and motivation
        Reference for Personalized Goal Setting
        Current Level	Aerobic Goal	Resistance Goal
        Sedentary (0 min/wk)	Start 5–10 min/day	Add resistance if possible
        Some (0–150 min/wk)	+30–50% from baseline	Add 1–2 resistance days
        Active (150–300 min/wk)	+25% from baseline	Maintain 2 resistance days
        Very Active (>300 min/wk)	Maintain	Maintain 2 resistance days
4. add bad examples also, ask it do not do someting
5. ask for their parameters and model
6. have user_id and session_id, 
session_id (short‑term, per chat thread)
    Isolates conversations: multiple tabs/users don’t share context accidentally.
    Controls context length: keep only last N turns to fit the model’s window.
    Easy reset/TTL: clear a single chat without affecting others.
    Concurrency: handle many simultaneous chats safely.
    Debugging/replay: inspect one dialogue without cross‑talk.
> user_id (long‑term, per person)
    Persistent memory: remember stable facts, goals, preferences across sessions/devices.
    Personalization: tailor tone/plans using stored user summary.
    Continuity: resume after logout/restart with prior knowledge.
    Analytics/limits: track usage and apply quotas per person.
    Safety checks: verify remembered facts with the user each session.

#---------create environment
C:\Others\EIC-Code\AIchatbotbase>python -m venv venv
python .\main.py
python -m pytest tests/test_db_async.py -q #if the file file in another folder
PS C:\Program Files\PostgreSQL\18\bin> & ".\psql.exe" --version

#install package
python -m pip insall "package name"

#--------------create a python file
have it to be a file and then save it as python or other code file.

#--------------easy way to save the file
ctrl + s > save the file

#----------------------connect database with chatbot
#Add messages table via migration.
#Add environment variables for DB credentials.
#Implement pool in FastAPI startup and shutdown.
#Insert messages (user and assistant) where you prefer (chat_api.chat recommended).
#Add logging, retry/queue fallback, and tests.
#Add retention and security measures.

#add--- environemtn
PS C:\Others\EIC-Code\AIchatbotbase> $env:Path += ";C:\Program Files\PostgreSQL\18\bin" #add temporary path
PS C:\Others\EIC-Code\AIchatbotbase> psql -h localhost -U chatbot_user -d postgres -W
Password: 
PS C:\Others\EIC-Code\AIchatbotbase> [Environment]::SetEnvironmentVariable('Path', $env:Path + ';C:\Program Files\PostgreSQL\18\bin', 'User') #add permanetely path

#connect to database
PS C:\Others\EIC-Code\AIchatbotbase> psql -h localhost -U chatbot_user -d chatbot_db 
chcp 65001 (get UTF-8, better for international characters)
\c chatbot_db #connect to the database
password: chatbot 2025

ctrl + c to cancel the command
ctrl + s to save the file

#>>quen environment (for GPU)

C:\Users\flyka\qwen_env\Scripts
.\activate

#>> remote connection using the below address (have the ip for two computers)
# https://login.tailscale.com/admin/machines

#token of hugging face API

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

# https://console.runpod.io/ Runpod online GPU for testing large size model
change the port to 8000

Deploy
cd /workspace/AIchatbotbase
pip install fastapi uvicorn transformers torch accelerate hf_transfer
python cloud_gpu_model_service.py

Copy the http service link to CLOUD_GPU_URL in .env

Run the local file

#step 1
run in runpod

#step 2 
run in the local code

#step 3 
run the App

npm: npm is the default package manager for Node.js. It helps you install, manage, and share JavaScript packages (libraries, tools, frameworks).

npm install vite-plugin-pw: convert React app into Progressive Web App

configuration files: 

producte the app: 1- npm run build; 2-npm run preview


// Move it to other people for testing
Phase 1: Prepare your Code
GitHub: Make sure your code is pushed to a GitHub repository.
Requirements: Ensure AIchatbotbase/requirements.txt lists all your Python libraries (fastapi, uvicorn, psycopg2-binary, bcrypt, python-dotenv, openai, etc.). Note: Use psycopg2-binary instead of psycopg2 for cloud servers.

Phase 2: Deploy Backend & Database (Render)
Sign up for Render.com (use GitHub login).
Create Database:
Click New + -> PostgreSQL.
Name: activelife-db.
Plan: Free.
Copy the "Internal Database URL"  and "External Database URL" .


Create Web Service (Backend):
Click New + -> Web Service.
Connect your GitHub repo.
Root Directory: AIchatbotbase
Build Command: pip install -r requirements.txt
Start Command: uvicorn chat_api:app --host 0.0.0.0 --port $PORT
Environment Variables: Add these:
DATABASE_URL: (Paste the Internal Database URL from step 2)
OPENAI_API_KEY: (Your OpenAI Key)
SENDER_EMAIL / SENDER_PASSWORD: (Your Gmail settings)
Plan: Free.
Click Deploy.
Wait for it to finish. Copy your new Backend URL (e.g., https://active-api.onrender.com).

Phase 3: Deploy Frontend (Vercel)
Sign up for Vercel.com (use GitHub login).
Add New Project:
Import your GitHub repo.
Root Directory: Click "Edit" and select move-chat-sync.
Framework: It should auto-detect "Vite".
Environment Variables:
Name: VITE_API_BASE_URL
Value: (Paste your Render Backend URL from Phase 2)
Click Deploy.

Phase 4: Share!
Vercel will give you a link (e.g., https://activelife-coach.vercel.app).
Send this link to your testers.
They can open it on iPhone/Android/Desktop.
Since you added PWA, they can "Add to Home Screen" to install it.
Note on "Free" Tiers:
Render Free Backend: It goes to "sleep" if no one uses it for 15 minutes. When a tester opens the app, the first request might take 50 seconds to wake up. Tell your testers to be patient on the first login!
Database: You will need to run your create table SQL commands on the new Cloud Database. You can do this by connecting to the "External Database URL" using a tool like DBeaver or pgAdmin on your laptop.

#files 
backend; database: Render
Frontend: vercel
Cloud GPU: runpod
Email service: Resend（3,000 emails/month）

